# üó∫Ô∏è AnythingLLM Embed Analytics - Roadmap

## ‚úÖ Phase 1: Conversation ID Tracking & RAG Context Fix (ABGESCHLOSSEN)

**Status:** ‚úÖ Vollst√§ndig implementiert & getestet (22.02.2026)

### Implementierte Features:
- ‚úÖ **Conversation ID System** (UUID v4)
  - Widget-getrieben: Neue UUID beim ersten Chat
  - Reset-Funktionalit√§t: Neue UUID bei "Clear Chat"
  - LocalStorage-Persistenz pro Embed

- ‚úÖ **RAG Context Fix** (HAUPTZIEL)
  - Backend nutzt `conversation_id` statt `session_id` f√ºr History-Retrieval
  - Alte Nachrichten erscheinen NICHT mehr im neuen Konversations-Context
  - **Problem gel√∂st:** RAG Context enth√§lt nur noch relevante Nachrichten

- ‚úÖ **Admin-UI: Konversations-Gruppierung**
  - Konversations-Karten statt Flat-Liste
  - "üÜï NEU" Badge f√ºr Konversationen <1h
  - Beide Zeitstempel: "Erstellt" (absolut) + "Letzte Nachricht" (relativ)
  - Expandable Details: Alle Nachrichten einer Konversation
  - Workspace-Name angezeigt

- ‚úÖ **Backwards Compatibility**
  - Alte Chats ohne `conversation_id` funktionieren weiter
  - Fallback: `conversation_id = session_id` f√ºr Legacy-Daten
  - Migration: 27 bestehende Chats automatisch migriert

### Technische Umsetzung:
- **Backend:** 4 Dateien (Schema, Models, Endpoints, Utils)
- **Frontend:** 4 Dateien (Models, UI, Translations)
- **Widget:** 8 Dateien (Hooks, Services, Components)
- **Database:** Prisma Migration + Index auf `conversation_id`

### Test-Ergebnisse:
- ‚úÖ Alle 19 Features getestet und funktionieren
- ‚úÖ E2E-Test: Widget ‚Üí Backend ‚Üí Database ‚Üí Admin-UI
- ‚úÖ RAG Context verifiziert: Konversationen getrennt
- ‚úÖ UI-Tests: Karten, Badge, Expand, Zeitstempel

---

## üìã Phase 2: LLM-basierte Analytics (GEPLANT)

**Ziel:** Intelligente Auswertung von Chat-Daten f√ºr Support & Business Insights

### 2.1 H√§ufigste Fragen / Themen-Clustering

**Technologie:** LLM Embeddings + K-Means Clustering

**Features:**
- [ ] Top 10 h√§ufigste Frage-Kategorien
  - Automatisches Clustering aller User-Prompts
  - Kategorie-Namen per LLM generieren
  - Anzahl Fragen pro Kategorie

- [ ] Trend-Analyse
  - Welche Fragen nehmen zu/ab?
  - Neue Frage-Kategorien erkennen
  - Zeitreihen-Diagramm

**Implementierung:**
```javascript
// Pseudocode
const prompts = await getAllUserPrompts(embedId, dateRange);
const embeddings = await getEmbeddings(prompts); // OpenAI/Local
const clusters = kMeansClustering(embeddings, k=10);

// F√ºr jedes Cluster: LLM generiert Kategorie-Namen
const categories = await Promise.all(
  clusters.map(cluster =>
    llm.chat(`Fasse diese Fragen in 2-3 Worten zusammen: ${cluster.samples}`)
  )
);
```

**UI-Komponente:**
```jsx
<TopQuestionsWidget>
  <QuestionCategory
    name="Kontoer√∂ffnung"
    count={45}
    trend="+12%"
    examples={["Wie √∂ffne ich ein Konto?", "Ben√∂tigte Dokumente?"]}
  />
  <QuestionCategory name="√ñffnungszeiten" count={32} trend="-5%" />
  ...
</TopQuestionsWidget>
```

**Aufwand:** ~2-3 Tage
**Abh√§ngigkeiten:** LLM Embeddings API (bereits vorhanden in AnythingLLM)

---

### 2.2 Sentiment-Analyse pro Konversation

**Technologie:** LLM-basiertes Sentiment (GPT/Local)

**Features:**
- [ ] Sentiment-Score pro Konversation
  - Positiv / Neutral / Negativ
  - Numerischer Score (-1 bis +1)
  - Sentiment-Verlauf √ºber Zeit

- [ ] Sentiment-Trigger erkennen
  - Wann kippt Sentiment von positiv zu negativ?
  - Welche Themen f√ºhren zu negativem Sentiment?

- [ ] Alerts f√ºr negative Konversationen
  - Email-Benachrichtigung bei stark negativem Sentiment
  - Eskalation an Support-Team

**Implementierung:**
```javascript
// Pro Konversation: Sentiment der letzten User-Nachricht analysieren
const sentiment = await llm.chat(
  `Analysiere das Sentiment dieser Nachricht: "${lastUserPrompt}"

   Antworte im JSON-Format:
   {
     "sentiment": "positiv|neutral|negativ",
     "score": 0.8,  // -1 (sehr negativ) bis +1 (sehr positiv)
     "reason": "Kunde ist zufrieden mit schneller Antwort"
   }`
);

// In Database speichern
await updateConversation(conversationId, {
  sentiment: sentiment.sentiment,
  sentiment_score: sentiment.score,
  sentiment_reason: sentiment.reason
});
```

**UI-Komponente:**
```jsx
<SentimentDashboard>
  <SentimentTrend data={sentimentHistory} />
  <NegativeConversations
    conversations={negativeConvs}
    onEscalate={escalateToSupport}
  />
  <SentimentDistribution positive={65} neutral={25} negative={10} />
</SentimentDashboard>
```

**Aufwand:** ~2 Tage
**Abh√§ngigkeiten:** LLM Chat API

---

### 2.3 Problematische Nachrichten erkennen

**Technologie:** LLM Moderation API + Custom Rules

**Features:**
- [ ] Toxicity-Erkennung
  - Schimpfw√∂rter, Beleidigungen, Bedrohungen
  - Spam, Phishing-Versuche
  - Policy-Verletzungen

- [ ] Automatisches Flagging
  - Problematische Nachrichten in DB markieren
  - Moderations-Queue f√ºr Review
  - Auto-Blockierung bei schweren Verst√∂√üen

- [ ] Moderation-Dashboard
  - Liste aller geflaggten Nachrichten
  - Review-Workflow (Approve/Reject/Block)
  - Statistiken: Toxicity-Rate, h√§ufigste Kategorien

**Implementierung:**
```javascript
// Bei jeder neuen User-Nachricht: Moderation-Check
const moderation = await openai.moderations.create({
  input: userPrompt
});

if (moderation.results[0].flagged) {
  const categories = moderation.results[0].categories;

  await flagMessage(chatId, {
    flagged: true,
    categories: categories, // hate, harassment, sexual, violence, etc.
    severity: moderation.results[0].category_scores
  });

  // Optional: Auto-Block bei schweren Verst√∂√üen
  if (categories.violence || categories.hate) {
    await blockSession(sessionId);
  }
}
```

**UI-Komponente:**
```jsx
<ModerationDashboard>
  <FlaggedMessages
    messages={flaggedList}
    onReview={(msgId, action) => reviewMessage(msgId, action)}
  />
  <ToxicityStats
    totalFlagged={156}
    byCategory={{ hate: 12, spam: 98, harassment: 46 }}
  />
</ModerationDashboard>
```

**Aufwand:** ~3 Tage
**Abh√§ngigkeiten:** OpenAI Moderation API (oder Alternative: Perspective API)

---

### Phase 2 Zusammenfassung

**Gesamtaufwand:** ~7-10 Tage
**Priorisierung:**
1. **High:** H√§ufigste Fragen (Top 10) ‚Üí Direkter Business Value
2. **Medium:** Sentiment-Analyse ‚Üí Support-Qualit√§t verbessern
3. **Low:** Problematische Nachrichten ‚Üí Nur bei Bedarf (z.B. √∂ffentliche Widgets)

**Neue Database-Felder:**
```prisma
model embed_chats {
  // ... existing fields ...
  sentiment          String?   // "positiv", "neutral", "negativ"
  sentiment_score    Float?    // -1 bis +1
  sentiment_reason   String?   // LLM-Begr√ºndung
  flagged            Boolean   @default(false)
  flag_categories    Json?     // Moderation-Kategorien
  flag_severity      Json?     // Severity-Scores
  reviewed_at        DateTime?
  reviewed_by        Int?
}
```

---

## üîÆ Phase 3: Advanced Features (ZUKUNFT)

**Langfristige Vision f√ºr Enterprise-Features**

### 3.1 Automatische FAQ-Generierung
- LLM analysiert h√§ufigste Fragen + beste Antworten
- Generiert automatisch FAQ-Dokumente
- Vorschl√§ge f√ºr Knowledge-Base-Artikel

### 3.2 Response-Quality-Scoring
- LLM bewertet Antwort-Qualit√§t (0-10)
- Erkennt unvollst√§ndige/ungenaue Antworten
- Vorschl√§ge f√ºr Verbesserungen im RAG-System

### 3.3 Konversations-Zusammenfassungen
- LLM generiert Zusammenfassung pro Konversation
- "User wollte Kontoer√∂ffnung, wurde erfolgreich weitergeleitet"
- Automatisches Tagging (Intent, Outcome, Satisfaction)

### 3.4 Predictive Analytics
- Vorhersage: Wird User konvertieren? (Lead Scoring)
- Churn-Risk-Erkennung (negatives Sentiment ‚Üí Abwanderung?)
- Beste Zeitpunkte f√ºr Proaktive Kontaktaufnahme

### 3.5 Multi-Language Support
- Automatische Sprach-Erkennung
- √úbersetzung f√ºr Analytics (alle Sprachen ‚Üí DE/EN)
- Sentiment-Analyse sprach√ºbergreifend

### 3.6 Integration mit externen Tools
- Slack-Benachrichtigungen bei kritischen Konversationen
- Zapier/Make.com Webhooks f√ºr Custom Workflows
- CRM-Integration (HubSpot, Salesforce)

---

## üìä Roadmap Timeline

```
Q1 2026:
‚îú‚îÄ ‚úÖ Phase 1: Conversation ID (DONE - Feb 2026)
‚îî‚îÄ üìã Phase 2.1: H√§ufigste Fragen (geplant - M√§rz 2026)

Q2 2026:
‚îú‚îÄ üìã Phase 2.2: Sentiment-Analyse (geplant - April 2026)
‚îî‚îÄ üìã Phase 2.3: Moderation (optional - Mai 2026)

Q3/Q4 2026:
‚îî‚îÄ üîÆ Phase 3: Evaluierung basierend auf User-Feedback
```

---

## üéØ Success Metrics

**Phase 1 (aktuell):**
- ‚úÖ RAG Context Accuracy: 100% (nur relevante Nachrichten)
- ‚úÖ Konversations-Gruppierung: Funktioniert
- ‚úÖ User Experience: "üÜï NEU" Badge + Zeitstempel

**Phase 2 (Ziel):**
- H√§ufigste Fragen: Top 10 identifiziert ‚Üí FAQ erstellen
- Sentiment: 80%+ Accuracy bei Positiv/Negativ-Erkennung
- Support-Effizienz: Negative Konversationen werden priorisiert

**Phase 3 (Vision):**
- FAQ-Automation: 50% weniger Support-Tickets
- Lead Conversion: +15% durch proaktive Kontaktaufnahme
- Churn Prevention: -20% Abwanderung durch fr√ºhzeitige Intervention

---

## ü§ù Contribution Guidelines

**Phase 2 beitragen:**
1. Issue erstellen mit Feature-Beschreibung
2. Design-Doc f√ºr gr√∂√üere Features (>3 Tage Aufwand)
3. Tests schreiben (E2E + Unit)
4. UI/UX mit Screenshots dokumentieren

**Technologie-Stack:**
- LLM: OpenAI GPT-4 oder Local (Ollama)
- Embeddings: OpenAI `text-embedding-3-small` oder Local
- Database: Prisma + SQLite (Production: PostgreSQL)
- Frontend: React + TailwindCSS

---

## üìù Changelog

### 2026-02-22 - Phase 1 Release
- ‚úÖ Conversation ID Tracking implementiert
- ‚úÖ RAG Context Fix (conversation_id statt session_id)
- ‚úÖ Admin-UI: Konversations-Gruppierung mit "üÜï NEU" Badge
- ‚úÖ Widget: UUID v4 Generation + Reset-Funktionalit√§t
- ‚úÖ Database Migration: 27 Chats migriert
- ‚úÖ Alle Tests bestanden (19/19 Features)

### 2026-02-22 - Roadmap erstellt
- üìã Phase 2 geplant: LLM-basierte Analytics
- üîÆ Phase 3 Vision: Advanced Enterprise Features
